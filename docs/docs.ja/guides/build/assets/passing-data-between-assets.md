---
title: アセット間でのデータの受け渡し
description: Learn how to pass data between assets in Dagster
sidebar_position: 300
---

Dagster では、アセットはデータ パイプラインの構成要素であり、アセット間でデータを渡すことが一般的です。このガイドは、アセット間でデータを渡す方法を理解するのに役立ちます。

アセット間でデータを渡す方法は 3 つあります:

- 外部ストレージを使用してデータを明示的に管理する
- I/Oマネージャを使用してデータを暗黙的に管理する
- 複数のタスクを1つのアセットにまとめることで、アセット間でのデータの受け渡しを完全に回避する

このガイドでは、3 つの方法すべてについて説明します。

:::note

この記事は、[アセット](/guides/build/assets/defining-assets)と[リソース](/guides/build/external-resources/)に精通していることを前提としています。

:::

<details>
  <summary>前提条件</summary>

この記事のコードを実行するには、Python 仮想環境を作成してアクティブ化し、次の依存関係をインストールする必要があります:

   ```bash
   pip install dagster dagster-duckdb-pandas
   ```
</details>

## 外部ストレージを使用してデータアセットを明示的に移動する

アセット間でデータを渡すための一般的な推奨アプローチは、外部ストレージを使用してデータを明示的に管理することです。このサンプル パイプラインでは、外部ストレージとして SQLite データベースを使用します:

<CodeExample path="docs_snippets/docs_snippets/guides/data-assets/passing-data-assets/passing-data-explicit.py" language="python" title="Using External Storage" />

この例では、最初のアセットは SQLite データベースへの接続を開き、そこにデータを書き込みます。2 番目のアセットは同じデータベースへの接続を開き、そこからデータを読み取ります。最初のアセットと 2 番目のアセット間の依存関係は、アセットの `deps` 引数によって明示的に示されます。

このアプローチの利点は次のとおりです:

- データの保存方法と取得方法が明確でわかりやすい
- 環境に応じてデータの保存方法や場所を柔軟に選択できる

このアプローチの欠点は次のとおりです:

- 接続とトランザクションを手動で管理する必要がある
- データベースがダウンしている場合や接続が閉じている場合など、エラーやエッジケースを処理する必要がある

## I/O マネージャーを使用してアセット間でデータを暗黙的に移動する

Dagster の I/O マネージャーは、外部ストレージからのデータの読み取りと外部ストレージへのデータの書き込み方法を定義することで、アセット間のデータを管理する強力な機能です。ビジネス ロジックを I/O 操作から分離し、定型コードを削減して、データの保存場所の変更を容易にします。

I/O マネージャーは以下を処理します:

1. **入力**: ストレージからデータを読み取り、依存するアセットで使用するためにメモリにロードします。
2. **出力**: 設定された保存場所にデータを書き込みます。

I/O マネージャーについてさらに詳しく知りたい場合は、[I/O マネージャーについて](/guides/build/io-managers/) ガイドをご覧ください。

<CodeExample path="docs_snippets/docs_snippets/guides/data-assets/passing-data-assets/passing-data-io-manager.py" language="python" title="Using I/O managers" />

この例では、`DuckDBPandasIOManager` がインスタンス化され、ローカルファイルを使用して実行されます。I/O マネージャーは、データベースの読み取りと書き込みの両方を処理します。

:::warning

この例はローカル開発では機能しますが、運用環境では各ステップが別の環境で実行され、同じファイルシステムにアクセスすることはできません。運用目的でクラウド ホスト環境を検討してください。

:::

`people()` アセットと `birds()` アセットは両方とも、永続的なストレージのためにデータフレームを DuckDB に書き込みます。`combined_data()` アセットは、両方のアセットからデータを要求し、それらを関数にパラメータとして追加します。I/O マネージャーは、それらを DuckDB から読み取り、それらをデータフレームとして `combined_data` 関数で使用できるようにします。**注**: I/O マネージャーを使用する場合、`deps` 引数を使用してアセットの依存関係を手動で追加する必要はありません。

このアプローチの利点は次のとおりです:

- データの読み取りと書き込みはI/Oマネージャによって処理され、定型コードが削減されます。
- 基盤となるアセット計算を変更することなく、環境に基づいて異なるI/Oマネージャーを簡単に交換できます。

このアプローチの欠点は次のとおりです:

- I/Oマネージャのアプローチは、データの読み取りやストレージへの書き込み方法をカスタマイズする必要がある場合、柔軟性が低くなります。
- 上書きするのが難しい命名規則など、一部の決定は I/O マネージャーによって自動的に行われる場合があります。

## アセットを組み合わせることでアセット間のデータの受け渡しを回避する

場合によっては、パイプラインのモデル化方法を慎重に検討することで、アセット間でのデータの受け渡しを回避できることがあります:

次の例を考えてみましょう:

<CodeExample path="docs_snippets/docs_snippets/guides/data-assets/passing-data-assets/passing-data-avoid.py" language="python" title="Avoid Passing Data Between Assets" />

この例では、Google ドライブから zip ファイルをダウンロードし、解凍して、データを Pandas DataFrame に読み込みます。これらの操作を実行するには、同じファイル システムで実行されている各アセットに依存します。

アセットは、データアセットではなく、タスクとしてモデル化されます。タスクとデータアセットの違いの詳細については、[アセットガイド](/guides/build/assets/) を参照してください。

このリファクタリングでは、`download_files`、`unzip_files`、および `load_data` アセットが 1 つのアセット `my_dataset` に結合されます。このアセットは、ファイルをダウンロードして解凍し、データをデータ ウェアハウスに読み込みます。

<CodeExample path="docs_snippets/docs_snippets/guides/data-assets/passing-data-assets/passing-data-rewrite-assets.py" language="python" title="Avoid Passing Data Between Assets" />

このアプローチでは、データの受け渡しは引き続き明示的に処理されますが、アセット間で行われるのではなく、単一のアセット内で行われます。このパイプラインでは、依然としてデータを処理するために十分なディスクとメモリが利用可能であると想定されますが、データセットが小さい場合はうまく機能します。

このアプローチの利点は次のとおりです:

- アセットの作成方法を定義するすべての計算が単一のアセット内に含まれているため、理解と維持が容易になる
- 外部ストレージに依存するよりも高速であり、追加のコンピューティング インスタンスをセットアップするオーバーヘッドも必要ない

このアプローチの欠点は次のとおりです:

- 処理されるデータ量について一定の仮定を立てている
- 関数は生成するデータと密接に結びついているため、アセット間で関数を再利用するのは難しい場合がある
- 実行している環境によっては、機能を交換できない場合があります。たとえば、クラウド環境で実行している場合は、ローカルファイルシステムにアクセスできない可能性があります。

## 関連するリソース

{/* TODO: add links to relevant API documentation here. */}
